{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1736f475-8f7b-4f47-8793-b7a4d6606a77",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Loaded\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Import python libraries\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import psycopg2 as db_connect\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('default')\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Libraries Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd845d4-4118-492b-8af3-982d1b6887b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Set up connection to fetch data from Queenspark\n",
    "'''\n",
    "\n",
    "host_name = 'queenspark-new.crqm6nr3vrbv.ap-southeast-1.rds.amazonaws.com'\n",
    "db_user = 'readonly'\n",
    "db_password = 'readonly'\n",
    "db_name = 'queenspark'\n",
    "\n",
    "connection = db_connect.connect(\n",
    "                                host=host_name,\n",
    "                                user=db_user,\n",
    "                                password=db_password,\n",
    "                                database=db_name\n",
    "                               )\n",
    " \n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2204da-337b-472e-88b9-9a13ca12b0fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.36 s, sys: 449 ms, total: 1.81 s\n",
      "Wall time: 58.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "Import latest prices\n",
    "'''\n",
    "\n",
    "query_price_price = '''\n",
    "SELECT entry_id, date, price_avg\n",
    "FROM price_price\n",
    "where 1=1\n",
    "  and period = 'w'\n",
    "  and date > '2022-05-30'\n",
    ";\n",
    "'''\n",
    "cursor.execute(query_price_price)\n",
    "result = cursor.fetchall()\n",
    "col_names = []\n",
    "for elt in cursor.description:\n",
    "    col_names.append(elt[0])\n",
    "price_master = pd.DataFrame(result, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a447fd-a118-44e4-9dd0-cf17a6708056",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Import forecasted price master\n",
    "'''\n",
    "\n",
    "query_forecast = '''\n",
    "SELECT entry_id, date, price_avg\n",
    "FROM price_price_forecasted\n",
    "where 1=1\n",
    "  and period = 'w'\n",
    ";\n",
    "'''\n",
    "cursor.execute(query_forecast)\n",
    "result = cursor.fetchall()\n",
    "col_names = []\n",
    "for elt in cursor.description:\n",
    "    col_names.append(elt[0])\n",
    "forecasted_master = pd.DataFrame(result, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf1808-9dde-4b7b-b887-97abde127a15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "Import as-is PCP weight master\n",
    "'''\n",
    "\n",
    "query_rank = '''\n",
    "SELECT \n",
    "\tt1.market_id,\n",
    "\tt1.entry_id,\n",
    "\tt1.market_score,\n",
    "\tt1.product_name,\n",
    "\tt1.variety_label,\n",
    "\tt1.grade_label,\n",
    "\tt1.other_attributes_label,\n",
    "\tt1.cultivation_label,\n",
    "\tt1.origin_region,\n",
    "\tt1.market_region,\n",
    "\tpmv.\"rank\" AS variety_factor_rank,\n",
    "\tpmg.\"rank\" AS grade_factor_rank,\n",
    "\tpmo.\"rank\" AS other_attributes_facor_rank,\n",
    "\tpmct.\"rank\" AS cultivation_factor_rank,\n",
    "\tpmr.\"rank\" AS region_factor_rank\n",
    "FROM (\n",
    "\t\tSELECT\n",
    "\t\t  pp.id   AS market_id,\n",
    "\t\t  pe.market_score AS market_score,\n",
    "\t\t  pe.id   AS entry_id,\n",
    "\t\t  pi.id   AS item_id,\n",
    "\t\t  pi.product_id AS product_id,\n",
    "\t\t  ip.name AS product_name,\n",
    "\t\t  pi.variety_raw,\n",
    "\t\t  via.id AS variety_id,\n",
    "\t\t  via.label  AS variety_label,\n",
    "\t\t  pi.grade_raw,\n",
    "\t\t  gia.id AS grade_id,\n",
    "\t\t  gia.label  AS grade_label,\n",
    "\t\t  oia.attribute_id AS other_attributes_id,\n",
    "\t\t  oia.label  AS other_attributes_label,\n",
    "\t\t  cultivation.type_id AS cultivation_type_id,\n",
    "\t\t  cultivation.attribute_id AS cultivation_attribute_id,\n",
    "\t\t  cultivation.\"label\" AS cultivation_label,\n",
    "\t\t  CASE\n",
    "\t\t   WHEN pi.origin_type = 'd' THEN 'domestic'\n",
    "\t\t   WHEN pi.origin_type = 'i' THEN 'imported'\n",
    "\t\t   END  AS origin_type,\n",
    "\t\t  por.id AS origin_region_id,\n",
    "\t\t  por.name_label AS origin_region,\n",
    "\t\t  cc.code AS origin_country_id,\n",
    "\t\t  cc.name  AS origin_country,\n",
    "\t\t  pr.id AS market_region_id,\n",
    "\t\t  pr.name_label AS market_region,\n",
    "\t\t  piu.unit_raw AS original_unit,\n",
    "\t\t  piu.unit_label AS normalized_unit,\n",
    "\t\t  piu.unit_rate,\n",
    "\t\t  CASE\n",
    "\t\t   WHEN piu.unit = 'p' THEN 'pound'\n",
    "\t\t   WHEN piu.unit = 'k' THEN 'kg'\n",
    "\t\t   END  AS final_unit\n",
    "\t\tFROM price_entry pe\n",
    "\t\t  JOIN price_item pi     ON pe.item_id = pi.id\n",
    "\t\t  JOIN price_productcountryprice pp ON pi.product_country_price_id = pp.id\n",
    "\t\t  LEFT JOIN price_item_attributes pia ON pi.id = pia.item_id\n",
    "\t\t  LEFT JOIN price_item_grades pig  ON pig.item_id = pi.id\n",
    "\t\t  LEFT JOIN price_region pr   ON pr.id = pe.region_id\n",
    "\t\t  LEFT JOIN price_region por   ON por.id = pi.origin_region_id\n",
    "\t\t  LEFT JOIN choice_country cc   ON cc.code = pi.origin_country_id\n",
    "\t\t  LEFT JOIN price_itemunit piu   ON piu.id = pe.item_unit_id\n",
    "\t\t  LEFT JOIN insight_product ip   ON ip.id = pi.product_id\n",
    "\t\t  LEFT JOIN insight_attribute via  ON via.id = pi.variety_id\n",
    "\t\t  LEFT JOIN insight_attribute gia  ON gia.id = pig.attribute_id\n",
    "\t\t  LEFT JOIN (\t\t   \t\t\t\t\n",
    "\t\t\t  \t\t\tSELECT \n",
    "\t\t\t\t\t\t\t\toct.type_id\n",
    "\t\t\t\t\t\t\t\t, oct.\"type\"\n",
    "\t\t\t\t\t\t\t\t, ia.id AS attribute_id\n",
    "\t\t\t\t\t\t\t\t, ia.\"label\" AS LABEL\n",
    "\t\t\t\t\t\t\tFROM insight_attribute ia\n",
    "\t\t\t\t\t\t\tJOIN (\n",
    "\t\t\t\t\t\t\t\tSELECT \n",
    "\t\t\t\t\t\t\t\t\tid AS type_id \n",
    "\t\t\t\t\t\t\t\t\t, type AS \"type\"\n",
    "\t\t\t\t\t\t\t\tFROM insight_attributetype\n",
    "\t\t\t\t\t\t\t\tWHERE 1=1\n",
    "\t\t\t\t\t\t\t\tAND \"type\" != 'cultivation_type'\n",
    "\t\t\t\t\t\t\t) oct ON ia.type_id = oct.type_id\n",
    "\t\t\t) oia      ON oia.attribute_id = pia.attribute_id\n",
    "\t\t  LEFT JOIN (\n",
    "\t\t  \t\t\t\tSELECT \n",
    "\t\t\t\t\t\t\t\tct.type_id\n",
    "\t\t\t\t\t\t\t\t, ct.\"type\"\n",
    "\t\t\t\t\t\t\t\t, ia.id AS attribute_id\n",
    "\t\t\t\t\t\t\t\t, ia.\"label\" AS LABEL\n",
    "\t\t\t\t\t\t\tFROM insight_attribute ia\n",
    "\t\t\t\t\t\t\tJOIN (\n",
    "\t\t\t\t\t\t\t\tSELECT \n",
    "\t\t\t\t\t\t\t\t\tid AS type_id \n",
    "\t\t\t\t\t\t\t\t\t, type AS \"type\"\n",
    "\t\t\t\t\t\t\t\tFROM insight_attributetype\n",
    "\t\t\t\t\t\t\t\tWHERE 1=1\n",
    "\t\t\t\t\t\t\t\tAND \"type\" = 'cultivation_type'\n",
    "\t\t\t\t\t\t\t) ct ON ia.type_id = ct.type_id\n",
    "\t\t\t) cultivation  ON cultivation.attribute_id = pia.attribute_id\n",
    ") t1\n",
    "LEFT JOIN price_marketfactor pmv ON t1.market_id = pmv.market_id AND t1.variety_id = pmv.variety_id \n",
    "LEFT JOIN price_marketfactor pmr ON t1.market_id = pmr.market_id AND t1.market_region_id = pmr.origin_region_id\n",
    "LEFT JOIN price_marketfactor pmg ON t1.market_id = pmg.market_id AND t1.grade_id = pmg.grade_id\n",
    "LEFT JOIN price_marketfactor pmo ON t1.market_id = pmo.market_id AND t1.other_attributes_id = pmo.attribute_id\n",
    "LEFT JOIN price_marketfactor pmct ON t1.market_id = pmct.market_id AND t1.cultivation_attribute_id = pmct.cultivation_type_id\n",
    ";\n",
    "'''\n",
    "cursor.execute(query_rank)\n",
    "result = cursor.fetchall()\n",
    "col_names = []\n",
    "for elt in cursor.description:\n",
    "    col_names.append(elt[0])\n",
    "asis_weight_master = pd.DataFrame(result, columns = col_names)\n",
    "\n",
    "asis_weight_master2 = asis_weight_master.fillna(0)\n",
    "asis_weight_master2['sum_squared_rank'] = asis_weight_master2['variety_factor_rank'] ** 2 + asis_weight_master2['region_factor_rank'] ** 2 + asis_weight_master2['grade_factor_rank'] ** 2 + asis_weight_master2['other_attributes_facor_rank'] ** 2 + asis_weight_master2['cultivation_factor_rank'] ** 2\n",
    "\n",
    "'''\n",
    "Minmax => Reverse scaled result => Make sum to 1\n",
    "'''\n",
    "def normalization(Series):\n",
    "    to_scale = Series[(Series != 0) & (Series.notnull())]\n",
    "    scaled = (to_scale - to_scale.min()) / (to_scale.max() - to_scale.min())\n",
    "    scaled_reverse = 1 - scaled\n",
    "    scaled_reverse.replace(0, scaled_reverse[scaled_reverse != 0].min() / 2, inplace = True)\n",
    "\n",
    "    Series = pd.concat([\n",
    "                        Series[(Series == 0) | (Series.isnull())],\n",
    "                        scaled_reverse\n",
    "             ]).sort_index()\n",
    "    normalizer = 1 / Series.sum()\n",
    "    Series = Series * normalizer\n",
    "    \n",
    "    if not Series.any():\n",
    "        Series.replace(np.nan, 1 / len(Series), inplace = True)\n",
    "    \n",
    "    return Series\n",
    "\n",
    "asis_weight_master2['normalized_rank'] = asis_weight_master2.groupby('market_id')['sum_squaed_rank'].apply(lambda Series : normalization(Series))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9f40f-fa72-4b2d-a588-fc423ee1a61a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "Import to-be PCP weight master\n",
    "'''\n",
    "\n",
    "query6 = '''\n",
    "WITH attr_T AS (\n",
    "\tSELECT\n",
    "\t\tpe.id AS entry_id\n",
    "\t\t, pi.id AS item_id\n",
    "\t\t, oia.id AS attribute_id\n",
    "\t\t, via.id AS variety_id\n",
    "\t\t, gia.id AS grade_id\n",
    "\tFROM price_entry pe\n",
    "\t\tJOIN price_item pi ON pe.item_id = pi.id\n",
    "\t\tLEFT JOIN price_item_attributes pia ON pi.id = pia.item_id -- To link price_item & insight_attribute\n",
    "\t\tLEFT JOIN insight_attribute oia  ON pia.attribute_id = oia.id -- TO link pia & insight_attribute\n",
    "\t\tLEFT JOIN price_item_grades pig  ON pi.id = pig.item_id -- To link price_item & insight_attribute\n",
    "\t\tLEFT JOIN insight_attribute gia  ON pig.attribute_id = gia.id -- TO link grade & insight_attribute\n",
    "\t\tLEFT JOIN insight_attribute via  ON pi.variety_id = via.id -- To link variety & insight_attribute\n",
    "\tWHERE 1=1\n",
    "\tand pi.status = any (array ['s', 'm', 'a'])\n",
    "\tand pi.is_active = true\n",
    "\tand pe.is_active = true\n",
    "\tand pe.representative_score > 0\n",
    ")\n",
    "\n",
    "\n",
    "SELECT\n",
    "\tpcp.id AS market_id\n",
    "\t, entry_T.*\n",
    "FROM price_entry pe\n",
    "LEFT JOIN price_item pi ON pe.item_id = pi.id\n",
    "LEFT JOIN price_productcountryprice pcp ON pi.product_country_price_id = pcp.id\n",
    "LEFT JOIN (\n",
    "\t\t\tSELECT\n",
    "\t\t\t\tentry_id\n",
    "\t\t\t\t, sum(COALESCE (attribute_sum , 0) + COALESCE (variety_sum , 0) + COALESCE (grade_sum , 0)) AS attribute_sum\n",
    "\t\t\tFROM (\n",
    "\t\t\t----------------------------------------attribute_T--------------------------------------------\n",
    "\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\tattribute_T.*\n",
    "\t\t\t\t\t\t, variety_T.variety_sum\n",
    "\t\t\t\t\t\t, grade_T.grade_sum\n",
    "\t\t\t\t\tFROM (\n",
    "\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\tentry_id\n",
    "\t\t\t\t\t\t\t, sum(COALESCE (supply_cnt, 0) + COALESCE (fulfillment_item_cnt, 0) + COALESCE (journal_cnt, 0)) AS attribute_sum\n",
    "\t\t\t\t\t\tFROM (\n",
    "\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\tsupply_T.*\n",
    "\t\t\t\t\t\t\t\t, fulfillment_T.fulfillment_item_cnt\n",
    "\t\t\t\t\t\t\t\t, journal_T.journal_cnt\n",
    "\t\t\t\t\t\t\tFROM (\n",
    "\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\tattr_T.entry_id\n",
    "\t\t\t\t\t\t\t\t\t\t, attr_T.attribute_id\n",
    "\t\t\t\t\t\t\t\t\t\t, count(csa.supply_id) AS supply_cnt\n",
    "\t\t\t\t\t\t\t\t\tFROM attr_T\n",
    "\t\t\t\t\t\t\t\t\tLEFT JOIN commerce_supply_attributes csa ON attr_T.attribute_id = csa.attribute_id\n",
    "\t\t\t\t\t\t\t\t\tGROUP BY attr_T.entry_id, attr_T.attribute_id\n",
    "\t\t\t\t\t\t\t) supply_T\n",
    "\t\t\t\t\t\t\tLEFT JOIN (\n",
    "\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\tattr_T.entry_id\n",
    "\t\t\t\t\t\t\t\t\t\t, attr_T.attribute_id\n",
    "\t\t\t\t\t\t\t\t\t\t, count(cf.id) AS fulfillment_item_cnt\n",
    "\t\t\t\t\t\t\t\t\tFROM attr_T\n",
    "\t\t\t\t\t\t\t\t\tLEFT JOIN commerce_fulfillmentitem cf ON attr_T.attribute_id = cf.attribute_id\n",
    "\t\t\t\t\t\t\t\t\tGROUP BY attr_T.entry_id, attr_T.attribute_id\n",
    "\t\t\t\t\t\t\t) fulfillment_T ON supply_T.entry_id = fulfillment_T.entry_id AND supply_T.attribute_id = fulfillment_T.attribute_id\n",
    "\t\t\t\t\t\t\tLEFT JOIN (\n",
    "\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\tattr_T.entry_id\n",
    "\t\t\t\t\t\t\t\t\t\t, attr_T.attribute_id\n",
    "\t\t\t\t\t\t\t\t\t\t, count(ijpa.id) AS journal_cnt\n",
    "\t\t\t\t\t\t\t\t\tFROM attr_T\n",
    "\t\t\t\t\t\t\t\t\tLEFT JOIN intelligence_journal_primary_attributes ijpa ON attr_T.attribute_id = ijpa.attribute_id\n",
    "\t\t\t\t\t\t\t\t\tGROUP BY attr_T.entry_id, attr_T.attribute_id\n",
    "\t\t\t\t\t\t\t) journal_T ON supply_T.entry_id = journal_T.entry_id AND supply_T.attribute_id = journal_T.attribute_id\n",
    "\t\t\t\t\t\t) t1\n",
    "\t\t\t\t\t\tGROUP BY entry_id\n",
    "\t\t\t\t\t) attribute_T\n",
    "\t\t\t\t\tLEFT JOIN (\n",
    "\t\t\t\t\t----------------------------------------variety_T--------------------------------------------\n",
    "\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\tentry_id\n",
    "\t\t\t\t\t\t\t\t, variety_sum\n",
    "\t\t\t\t\t\t\tFROM (\n",
    "\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\tentry_id\n",
    "\t\t\t\t\t\t\t\t\t\t, sum(COALESCE (supply_cnt, 0) + COALESCE (fulfillment_item_cnt, 0) + COALESCE (journal_cnt, 0)) AS variety_sum\n",
    "\t\t\t\t\t\t\t\t\tFROM (\n",
    "\t\t\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tsupply_T.*\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t, fulfillment_T.fulfillment_item_cnt\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t, journal_T.journal_cnt\n",
    "\t\t\t\t\t\t\t\t\t\t\tFROM (\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tattr_T.entry_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t, attr_T.variety_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t, count(csa.supply_id) AS supply_cnt\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tFROM attr_T\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tLEFT JOIN commerce_supply_attributes csa ON attr_T.variety_id = csa.attribute_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tGROUP BY attr_T.entry_id, attr_T.variety_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t) supply_T\n",
    "\t\t\t\t\t\t\t\t\t\t\tLEFT JOIN (\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tattr_T.entry_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t, attr_T.variety_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t, count(cf.id) AS fulfillment_item_cnt\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tFROM attr_T\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tLEFT JOIN commerce_fulfillmentitem cf ON attr_T.variety_id = cf.attribute_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tGROUP BY attr_T.entry_id, attr_T.variety_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t) fulfillment_T ON supply_T.entry_id = fulfillment_T.entry_id AND supply_T.variety_id = fulfillment_T.variety_id\n",
    "\t\t\t\t\t\t\t\t\t\t\tLEFT JOIN (\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tattr_T.entry_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t, attr_T.variety_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t, count(ijpa.id) AS journal_cnt\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tFROM attr_T\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tLEFT JOIN intelligence_journal_primary_attributes ijpa ON attr_T.variety_id = ijpa.attribute_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tGROUP BY attr_T.entry_id, attr_T.variety_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t) journal_T ON supply_T.entry_id = journal_T.entry_id AND supply_T.variety_id = journal_T.variety_id\n",
    "\t\t\t\t\t\t\t\t\t) t2\n",
    "\t\t\t\t\t\t\t\t\tGROUP BY entry_id\n",
    "\t\t\t\t\t\t\t) variety\n",
    "\t\t\t\t\t) variety_T ON attribute_T.entry_id = variety_T.entry_id\n",
    "\t\t\t\t\tLEFT JOIN (\n",
    "\t\t\t\t\t----------------------------------------grade_T--------------------------------------------\n",
    "\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\tentry_id\n",
    "\t\t\t\t\t\t\t\t, grade_sum\n",
    "\t\t\t\t\t\t\tFROM (\n",
    "\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\tentry_id\n",
    "\t\t\t\t\t\t\t\t\t\t, sum(COALESCE (supply_cnt, 0) + COALESCE (fulfillment_item_cnt, 0) + COALESCE (journal_cnt, 0)) AS grade_sum\n",
    "\t\t\t\t\t\t\t\t\tFROM (\n",
    "\t\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\t\tsupply_T.*\n",
    "\t\t\t\t\t\t\t\t\t\t\t, fulfillment_T.fulfillment_item_cnt\n",
    "\t\t\t\t\t\t\t\t\t\t\t, journal_T.journal_cnt\n",
    "\t\t\t\t\t\t\t\t\t\tFROM (\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tattr_T.entry_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t, attr_T.grade_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t, count(csa.supply_id) AS supply_cnt\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tFROM attr_T\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tLEFT JOIN commerce_supply_attributes csa ON attr_T.grade_id = csa.attribute_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tGROUP BY attr_T.entry_id, attr_T.grade_id\n",
    "\t\t\t\t\t\t\t\t\t\t) supply_T\n",
    "\t\t\t\t\t\t\t\t\t\tLEFT JOIN (\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tattr_T.entry_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t, attr_T.grade_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t, count(cf.id) AS fulfillment_item_cnt\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tFROM attr_T\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tLEFT JOIN commerce_fulfillmentitem cf ON attr_T.grade_id = cf.attribute_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tGROUP BY attr_T.entry_id, attr_T.grade_id\n",
    "\t\t\t\t\t\t\t\t\t\t) fulfillment_T ON supply_T.entry_id = fulfillment_T.entry_id AND supply_T.grade_id = fulfillment_T.grade_id\n",
    "\t\t\t\t\t\t\t\t\t\tLEFT JOIN (\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tattr_T.entry_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t, attr_T.grade_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t, count(ijpa.id) AS journal_cnt\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tFROM attr_T\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tLEFT JOIN intelligence_journal_primary_attributes ijpa ON attr_T.grade_id = ijpa.attribute_id\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tGROUP BY attr_T.entry_id, attr_T.grade_id\n",
    "\t\t\t\t\t\t\t\t\t\t) journal_T ON supply_T.entry_id = journal_T.entry_id AND supply_T.grade_id = journal_T.grade_id\n",
    "\t\t\t\t\t\t\t\t\t) t3\n",
    "\t\t\t\t\t\t\t\t\tGROUP BY entry_id\n",
    "\t\t\t\t\t\t\t) grade\n",
    "\t\t\t\t\t\t) grade_T ON attribute_T.entry_id = grade_T.entry_id\n",
    "\t\t\t) total_T\n",
    "\t\t\tGROUP BY entry_id\n",
    "\t\t) entry_T ON pe.id = entry_T.entry_id\n",
    "WHERE 1=1\n",
    "and pi.status = any (array ['s', 'm', 'a'])\n",
    "and pi.is_active = true\n",
    "and pe.is_active = true\n",
    "and pe.representative_score > 0\n",
    ";\n",
    "'''\n",
    "cursor.execute(query6)\n",
    "result = cursor.fetchall()\n",
    "col_names = []\n",
    "for elt in cursor.description:\n",
    "    col_names.append(elt[0])\n",
    "tobe_weight_master = pd.DataFrame(result, columns = col_names)\n",
    "\n",
    "def softmax(Series):\n",
    "    scaled_Series = (Series - Series.min()) / (Series.max() - Series.min())\n",
    "    if not scaled_Series.any():\n",
    "        scaled_Series.replace(np.nan, 1 / len(scaled_Series), inplace = True)\n",
    "\n",
    "    exp_Series = np.exp(scaled_Series)\n",
    "    sum_exp_Series = np.sum(exp_Series)\n",
    "    soft_max = exp_Series / sum_exp_Series\n",
    "    return soft_max\n",
    "\n",
    "tobe_weight_master['attribute_sum'] = tobe_weight_master['attribute_sum'].astype(int)\n",
    "tobe_weight_master['soft_max'] = tobe_weight_master.groupby(['market_id']).apply(lambda df: softmax(df['attribute_sum'])).reset_index().set_index('level_1').drop('market_id', axis=1)\n",
    "tobe_weight_master2 = tobe_weight_master.copy()\n",
    "tobe_weight_master2['normalized_rank'] = tobe_weight_master2['soft_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e3948-68e2-4add-adce-d0826d11cce9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Import raw csv files(whitelist entries as of 2022-05-30)\n",
    "'''\n",
    "\n",
    "whitelisted = pd.read_csv('../CSV/Whitelisted.csv')\n",
    "entry_master = pd.read_csv('../CSV/Entry_Master.csv')\n",
    "product_master = pd.read_csv('../CSV/Product_Master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b759b0-b11f-4207-abc0-c1c9294fd90f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Raw data tables \n",
    "'''\n",
    "\n",
    "print('''\n",
    "Ready tables:\n",
    "\n",
    "whitelisted\n",
    "entry_master\n",
    "product_master\n",
    "price_master\n",
    "forecasted_master\n",
    "asis_weight_master2\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f15424f-a5d2-44fa-97a8-d8b615ccede1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Initial data cleansing and table processing\n",
    "Index start date = '2020-01-01'\n",
    "'''\n",
    "\n",
    "price_master['date'] = price_master['date'].astype(str)\n",
    "forecasted_master['date'] = forecasted_master['date'].astype(str)\n",
    "\n",
    "price_master_filter = price_master[price_master['entry_id'].isin(list(whitelisted['entry_id'].unique()))]\n",
    "price_master_filter['market_id'] = np.nan\n",
    "price_master_filter = price_master_filter[['market_id', 'entry_id', 'date', 'price_avg']].drop_duplicates()\n",
    "actual = pd.concat([whitelisted[['market_id', 'entry_id', 'date', 'price_avg']], price_master_filter], axis = 0).sort_values(by = ['entry_id','date'], ascending = [True, True])\n",
    "actual['market_id'] = actual.groupby('entry_id')['market_id'].transform('first')\n",
    "\n",
    "forecast = pd.merge(forecasted_master, entry_master[['market_id', 'entry_id']].drop_duplicates(), on = 'entry_id', how = 'left')\n",
    "forecast = forecast[['market_id', 'entry_id', 'date', 'price_avg']]\n",
    "forecast = forecast[~forecast['date'].isin(list(actual['date'].unique()))]\n",
    "\n",
    "df_raw = pd.concat([actual, forecast], axis = 0).sort_values(by = ['entry_id','date'], ascending = [True, True])\n",
    "df_raw_play = df_raw[df_raw['date'] >= '2020-01-01']\n",
    "unique_entry_lst = df_raw_play['entry_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377fcf52-28db-4027-a952-167540b91ee2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for imputation type #1\n",
    "'''\n",
    "\n",
    "def first_price(DataFrame, start = '2020-01-01', end=forecast['date'].max(), freq='w-Mon', unique_entry_lst = unique_entry_lst):\n",
    "    time_index= pd.date_range(start=start, end=end, freq=freq)\n",
    "    empty_DataFrame = pd.DataFrame(columns = DataFrame.columns)\n",
    "    #unique_entry_lst = list(DataFrame['entry_id'].unique())\n",
    "    \n",
    "    for uniq in tqdm(unique_entry_lst):\n",
    "        no_time = 0\n",
    "        new_DataFrame = DataFrame[DataFrame['entry_id'] == uniq].reset_index(drop=True)\n",
    "\n",
    "        while True:\n",
    "            # when first value isn't existed\n",
    "            if new_DataFrame['date'].iloc[0] != time_index[no_time].strftime('%Y-%m-%d'):\n",
    "                no_time += 1\n",
    "            # when first value is equal to time_index\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if no_time != 0:\n",
    "            for i in range(0, no_time):\n",
    "                new_row = new_DataFrame.iloc[0]\n",
    "                new_row['date'] = time_index[i].strftime('%Y-%m-%d')\n",
    "                empty_DataFrame = empty_DataFrame.append(new_row)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    DataFrame = pd.concat([DataFrame, empty_DataFrame], axis = 0).sort_values(by = ['entry_id','date'], ascending = [True, True]).reset_index(drop=True)\n",
    "    \n",
    "    return DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151bac2-6bef-4c00-824f-c332b62a2ac6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for imputation type #2\n",
    "'''\n",
    "\n",
    "def mean_price(DataFrame, unique_entry_lst = unique_entry_lst):\n",
    "    #unique_entry_lst = list(DataFrame['entry_id'].unique())\n",
    "    empty_DataFrame = pd.DataFrame(columns = DataFrame.columns)\n",
    "    \n",
    "    for uniq in unique_entry_lst:\n",
    "        new_DataFrame = DataFrame[DataFrame['entry_id'] == uniq].reset_index(drop=True)\n",
    "        null_lst = new_DataFrame[new_DataFrame['price_avg'].isna()].index.tolist()\n",
    "\n",
    "        for i in null_lst:\n",
    "            before_price = new_DataFrame['price_avg'].iloc[i - 1]\n",
    "            j = 1\n",
    "            check_price = new_DataFrame['price_avg'].iloc[i + j]\n",
    "\n",
    "            # check nan\n",
    "            while True:\n",
    "                # if nana\n",
    "                if float(check_price) != check_price:\n",
    "                    j += 1\n",
    "                    check_price = new_DataFrame['price_avg'].iloc[i + j]\n",
    "\n",
    "                else:\n",
    "                    next_price = float(check_price)\n",
    "                    break\n",
    "\n",
    "            new_DataFrame['price_avg'].iloc[i] = (before_price + next_price) / 2\n",
    "            \n",
    "        empty_DataFrame = empty_DataFrame.append(new_DataFrame)\n",
    "\n",
    "    return empty_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3673b4-bfdc-4ab0-9336-4a5d81b1f0c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for double checking if we have full time range prices for all entries\n",
    "'''\n",
    "\n",
    "def full_time_range(DataFrame, unique_entry_lst = unique_entry_lst):\n",
    "    empty_DataFrame = pd.DataFrame(columns = DataFrame.columns)\n",
    "\n",
    "    time_df = pd.DataFrame(pd.date_range(start='2020-01-01', end=forecast['date'].max(), freq='w-Mon'), columns = {'date'})\n",
    "    time_df['date'] = time_df['date'].astype(str)\n",
    "\n",
    "    for uniq in unique_entry_lst:\n",
    "        new_DataFrame = DataFrame[DataFrame['entry_id'] == uniq].reset_index(drop = True)\n",
    "        if len(new_DataFrame) == len(time_df):\n",
    "            new_DataFrame = new_DataFrame.copy()\n",
    "        else:\n",
    "            new_DataFrame = pd.merge(time_df, new_DataFrame, on = 'date', how = 'left')\n",
    "            new_DataFrame.loc[new_DataFrame['price_avg'].isna(), 'price_avg'] = new_DataFrame.loc[new_DataFrame['price_avg'].notnull(), 'price_avg'].iloc[-1]\n",
    "            new_DataFrame['market_id'] = new_DataFrame['market_id'].iloc[0]\n",
    "            new_DataFrame['entry_id'] = new_DataFrame['entry_id'].iloc[0]\n",
    "        \n",
    "        empty_DataFrame = empty_DataFrame.append(new_DataFrame)\n",
    "\n",
    "    return empty_DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1492119-f0ef-428d-8ad8-392b691598c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for computing final market index\n",
    "'''\n",
    "\n",
    "def calculate_market_index(DataFrame, weightedDataFrame, column_name, unique_entry_lst = unique_entry_lst):\n",
    "\n",
    "    relative_changes = []\n",
    "\n",
    "    for uniq in tqdm(unique_entry_lst):\n",
    "        new_DataFrame = DataFrame[DataFrame['entry_id'] == uniq].reset_index(drop = True)\n",
    "        new_DataFrame['price_avg'] = new_DataFrame['price_avg'].astype(float)\n",
    "        new_DataFrame['base_price'] = float(new_DataFrame['price_avg'][0])\n",
    "        new_DataFrame['relative_change'] = (( new_DataFrame['price_avg'] - new_DataFrame['base_price'] ) / new_DataFrame['base_price']) * 100\n",
    "        entry_weight = float(weightedDataFrame[weightedDataFrame['entry_id'] == uniq][column_name].unique())\n",
    "        relative_changes.append(np.array(new_DataFrame['relative_change'] * entry_weight))\n",
    "\n",
    "    market_final_change = np.sum(relative_changes, axis=0)\n",
    "    result_df = DataFrame[['market_id', 'date']].drop_duplicates()\n",
    "    result_df['market_final_change'] = market_final_change\n",
    "    result_df['market_index'] = 100 + market_final_change\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9dcf2-2381-4830-903d-4c0ac3a8a082",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for producing visualization graph\n",
    "'''\n",
    "\n",
    "def draw_avg_rate(DataFrame, market_id, country, item):\n",
    "    df = DataFrame[DataFrame['market_id'] == market_id]\n",
    "    plt.figure(figsize = (24, 10))\n",
    "    plt.plot(df['date'], df['market_index'], linestyle='-', marker='o', color='black')\n",
    "\n",
    "    plt.legend(labels = ['Relative Index'], fontsize = 12, loc = 'best')\n",
    "    plt.xlabel('Date', fontsize = 8)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Index(Base=100)')\n",
    "    plt.title('Market id: {}, Country: {}, Product: {}'.format(market_id, country, item), fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c2e38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for producing multiple visualization graphs\n",
    "'''\n",
    "\n",
    "def draw_avg_rate2(DataFrame1, DataFrame2, market_id, country, item):\n",
    "    df1 = DataFrame1[DataFrame1['market_id'] == market_id]\n",
    "    df2 = DataFrame2[DataFrame2['market_id'] == market_id]\n",
    "    plt.figure(figsize = (24, 10))\n",
    "    plt.plot(df1['date'], df1['market_index'], linestyle='-', marker='o', color='black')\n",
    "    plt.plot(df2['date'], df2['market_index'], linestyle='-', marker='o', color='red')\n",
    "\n",
    "    plt.legend(labels = ['Relative Index'], fontsize = 12, loc = 'best')\n",
    "    plt.xlabel('Date', fontsize = 8)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Index(Base=100)')\n",
    "    plt.title('Market id: {}, Country: {}, Product: {}'.format(market_id, country, item), fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa951a78-b7a7-4e24-8433-495d99e345eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Sample market information\n",
    "'''\n",
    "\n",
    "market_info = {42: \"Fresh Avocado, MX\",\n",
    "               212: \"Fresh Orange, EG\",\n",
    "               977: \"Raw Cashew Nut, TZ\",\n",
    "               596: \"Fresh Avocado, PE\",\n",
    "               566: \"Fresh Tahiti Lime, MX\",\n",
    "               63: \"Fresh Mature Coconut, IN\",\n",
    "               239: \"Fresh Apple, TR\",\n",
    "               1148: \"Chicken Egg, TR\",\n",
    "               1397: \"Radish, KR\",\n",
    "               136: \"Fresh Mango, PE\",\n",
    "               7530: \"Saffron, IR\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341fd876-c177-4ff5-adc0-a96c3f4cab7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generate market index for selected single market [AS-IS weight system]\n",
    "'''\n",
    "\n",
    "market_id = 596\n",
    "\n",
    "# start with\n",
    "df_check = df_raw_play[df_raw_play['market_id'] == market_id]\n",
    "unique_entry_lst = list(df_check['entry_id'].unique())\n",
    "\n",
    "# asis dictionary\n",
    "asis_key = list(asis_weight_master2[asis_weight_master2['entry_id'].isin(unique_entry_lst)]['entry_id'])\n",
    "asis_value = list(asis_weight_master2[asis_weight_master2['entry_id'].isin(unique_entry_lst)]['normalized_rank'])\n",
    "asis_weight_dic = dict(zip(asis_key, asis_value))\n",
    "\n",
    "df_check = df_check[df_check['entry_id'].isin(asis_key)]\n",
    "unique_entry_lst = list(df_check['entry_id'].unique())\n",
    "\n",
    "df_check2 = first_price(DataFrame = df_check, start = '2020-01-01', end=forecast['date'].max(), freq='w-Mon', unique_entry_lst = unique_entry_lst)\n",
    "df_check3 = mean_price(DataFrame = df_check2, unique_entry_lst = unique_entry_lst)\n",
    "df_check4 = full_time_range(DataFrame = df_check3, unique_entry_lst = unique_entry_lst)\n",
    "final_index = calculate_market_index(DataFrame = df_check4, weightedDataFrame = asis_weight_master2, column_name = 'normalized_rank', unique_entry_lst = unique_entry_lst)\n",
    "draw_avg_rate(final_index, market_id=market_id, country=market_info[market_id].split(\",\")[1], item=market_info[market_id].split(\",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca06182-caa0-4511-9fec-290764600cb8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "Generate market index for all sample markets [AS-IS weight system]\n",
    "'''\n",
    "\n",
    "final_df = list()\n",
    "for market_id in market_info.keys():\n",
    "    # start with\n",
    "    df_check = df_raw_play[df_raw_play['market_id'] == market_id]\n",
    "    unique_entry_lst = list(df_check['entry_id'].unique())\n",
    "\n",
    "    # asis dictionary\n",
    "    asis_key = list(asis_weight_master2[asis_weight_master2['entry_id'].isin(unique_entry_lst)]['entry_id'])\n",
    "    asis_value = list(asis_weight_master2[asis_weight_master2['entry_id'].isin(unique_entry_lst)]['normalized_rank'])\n",
    "    asis_weight_dic = dict(zip(asis_key, asis_value))\n",
    "\n",
    "    df_check = df_check[df_check['entry_id'].isin(asis_key)]\n",
    "    unique_entry_lst = list(df_check['entry_id'].unique())\n",
    "\n",
    "    if len(unique_entry_lst) == 0:\n",
    "        print('Failed market_id: {}'.format(market_id))\n",
    "        continue\n",
    "    else:\n",
    "        df_check2 = first_price(DataFrame = df_check, start = '2020-01-01', end=forecast['date'].max(), freq='w-Mon', unique_entry_lst = unique_entry_lst)\n",
    "        df_check3 = mean_price(DataFrame = df_check2, unique_entry_lst = unique_entry_lst)\n",
    "        df_check4 = full_time_range(DataFrame = df_check3, unique_entry_lst = unique_entry_lst)\n",
    "        globals()['market_entry_df_%s' % market_id] = df_check4.copy()\n",
    "        globals()['market_index_df_%s' % market_id] = calculate_market_index(DataFrame = df_check4, weightedDataFrame = asis_weight_master2, column_name = 'normalized_rank', unique_entry_lst = unique_entry_lst)\n",
    "        print('Completed market_id: {}'.format(market_id))\n",
    "\n",
    "    final_df.append(globals()['market_index_df_%s' % market_id])\n",
    "final_df = pd.concat(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761a834",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generate market index for selected single market [TO-BE weight system]\n",
    "'''\n",
    "\n",
    "market_id = 596\n",
    "\n",
    "# start with\n",
    "df_check = df_raw_play[df_raw_play['market_id'] == market_id]\n",
    "unique_entry_lst = list(df_check['entry_id'].unique())\n",
    "\n",
    "# asis dictionary\n",
    "tobe_key = list(tobe_weight_master2[tobe_weight_master2['entry_id'].isin(unique_entry_lst)]['entry_id'])\n",
    "tobe_value = list(tobe_weight_master2[tobe_weight_master2['entry_id'].isin(unique_entry_lst)]['normalized_rank'])\n",
    "tobe_weight_dic = dict(zip(tobe_key, tobe_value))\n",
    "\n",
    "df_check = df_check[df_check['entry_id'].isin(tobe_key)]\n",
    "unique_entry_lst = list(df_check['entry_id'].unique())\n",
    "\n",
    "df_check2 = first_price(DataFrame = df_check, start = '2020-01-01', end=forecast['date'].max(), freq='w-Mon', unique_entry_lst = unique_entry_lst)\n",
    "df_check3 = mean_price(DataFrame = df_check2, unique_entry_lst = unique_entry_lst)\n",
    "df_check4 = full_time_range(DataFrame = df_check3, unique_entry_lst = unique_entry_lst)\n",
    "final_index = calculate_market_index(DataFrame = df_check4, weightedDataFrame = tobe_weight_master2, column_name = 'normalized_rank', unique_entry_lst = unique_entry_lst)\n",
    "draw_avg_rate(final_index, market_id=market_id, country=market_info[market_id].split(\",\")[1], item=market_info[market_id].split(\",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a003571",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "Generate market index for all sample markets [TO-BE weight system]\n",
    "'''\n",
    "\n",
    "final_df2 = list()\n",
    "for market_id in market_info.keys():\n",
    "    # start with\n",
    "    df_check = df_raw_play[df_raw_play['market_id'] == market_id]\n",
    "    unique_entry_lst = list(df_check['entry_id'].unique())\n",
    "\n",
    "    # asis dictionary\n",
    "    tobe_key = list(tobe_weight_master2[tobe_weight_master2['entry_id'].isin(unique_entry_lst)]['entry_id'])\n",
    "    tobe_value = list(tobe_weight_master2[tobe_weight_master2['entry_id'].isin(unique_entry_lst)]['normalized_rank'])\n",
    "    tobe_weight_dic = dict(zip(tobe_key, tobe_value))\n",
    "\n",
    "    df_check = df_check[df_check['entry_id'].isin(tobe_key)]\n",
    "    unique_entry_lst = list(df_check['entry_id'].unique())\n",
    "\n",
    "    if len(unique_entry_lst) == 0:\n",
    "        print('Failed market_id: {}'.format(market_id))\n",
    "        continue\n",
    "    else:\n",
    "        df_check2 = first_price(DataFrame = df_check, start = '2020-01-01', end=forecast['date'].max(), freq='w-Mon', unique_entry_lst = unique_entry_lst)\n",
    "        df_check3 = mean_price(DataFrame = df_check2, unique_entry_lst = unique_entry_lst)\n",
    "        df_check4 = full_time_range(DataFrame = df_check3, unique_entry_lst = unique_entry_lst)\n",
    "        globals()['market_entry_df_%s' % market_id] = df_check4.copy()\n",
    "        globals()['market_index_df_%s' % market_id] = calculate_market_index(DataFrame = df_check4, weightedDataFrame = tobe_weight_master2, column_name = 'normalized_rank', unique_entry_lst = unique_entry_lst)\n",
    "        print('Completed market_id: {}'.format(market_id))\n",
    "\n",
    "    final_df2.append(globals()['market_index_df_%s' % market_id])\n",
    "final_df2 = pd.concat(final_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61dcca7-24e6-407d-b74d-d97fc6f5a677",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for market_id in market_info.keys():\n",
    "    draw_avg_rate2(final_df, final_df2, market_id=market_id, country=market_info[market_id].split(\",\")[1], item=market_info[market_id].split(\",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf0036",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(list(whitelisted['market_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4c751-af5d-4ba0-8fb5-20389bdb35e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "as_is_cov = asis_weight_master2.copy()\n",
    "as_is_cov['sum'] = asis_weight_master2['variety_factor_rank'] + asis_weight_master2['grade_factor_rank'] + asis_weight_master2['other_attributes_facor_rank'] + asis_weight_master2['cultivation_factor_rank'] + asis_weight_master2['region_factor_rank']\n",
    "as_is_cov = as_is_cov[as_is_cov['sum']!=0]\n",
    "len(as_is_cov['market_id'].unique()), len(as_is_cov[as_is_cov['market_id'].isin(list(whitelisted['market_id'].unique()))]['market_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac66a3-4670-4af1-a93a-33da242dfb45",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "to_be_cov = tobe_weight_master2.copy()\n",
    "len(to_be_cov['market_id'].unique()), len(to_be_cov[to_be_cov['market_id'].isin(list(whitelisted['market_id'].unique()))]['market_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979f33a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
